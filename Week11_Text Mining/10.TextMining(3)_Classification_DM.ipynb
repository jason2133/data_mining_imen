{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4470117",
   "metadata": {},
   "source": [
    "## 뉴스그룹 데이터 준비 및 특성 추출\n",
    "http://scikit-learn.org/0.19/datasets/twenty_newsgroups.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b714e678",
   "metadata": {},
   "source": [
    "fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dacf446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "\n",
    "from pprint import pprint\n",
    "print(list(newsgroups_train.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fed7318",
   "metadata": {},
   "source": [
    "데이터 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6936abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Train set size: 2034\n",
      "#Test set size: 1353\n",
      "#Selected categories: ['alt.atheism', 'comp.graphics', 'sci.space', 'talk.religion.misc']\n",
      "#Train labels: {0, 1, 2, 3}\n"
     ]
    }
   ],
   "source": [
    "#20개의 토픽 중 선택하고자 하는 토픽을 리스트로 생성\n",
    "categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
    "\n",
    "#학습 데이터셋을 가져옴\n",
    "newsgroups_train = fetch_20newsgroups(subset='train',\n",
    "#메일 내용에서 hint가 되는 부분을 삭제 - 순수하게 내용만으로 분류\n",
    "                                      remove=('headers', 'footers', 'quotes'),\n",
    "                                      categories=categories)\n",
    "#검증 데이터셋을 가져옴\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', \n",
    "                                     remove=('headers', 'footers', 'quotes'),\n",
    "                                     categories=categories)\n",
    "\n",
    "print('#Train set size:', len(newsgroups_train.data))\n",
    "print('#Test set size:', len(newsgroups_test.data))\n",
    "print('#Selected categories:', newsgroups_train.target_names)\n",
    "print('#Train labels:', set(newsgroups_train.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c4b3416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Train set text samples: Hi,\n",
      "\n",
      "I've noticed that if you only save a model (with all your mapping planes\n",
      "positioned carefully) to a .3DS file that when you reload it after restarting\n",
      "3DS, they are given a default position and orientation.  But if you save\n",
      "to a .PRJ file their positions/orientation are preserved.  Does anyone\n",
      "know why this information is not stored in the .3DS file?  Nothing is\n",
      "explicitly said in the manual about saving texture rules in the .PRJ file. \n",
      "I'd like to be able to read the texture rule information, does anyone have \n",
      "the format for the .PRJ file?\n",
      "\n",
      "Is the .CEL file format available from somewhere?\n",
      "\n",
      "Rych\n",
      "#Train set label smaples: 1\n",
      "#Test set text samples: TRry the SKywatch project in  Arizona.\n",
      "#Test set label smaples: 2\n"
     ]
    }
   ],
   "source": [
    "print('#Train set text samples:', newsgroups_train.data[0])\n",
    "print('#Train set label smaples:', newsgroups_train.target[0])\n",
    "print('#Test set text samples:', newsgroups_test.data[0])\n",
    "print('#Test set label smaples:', newsgroups_test.target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4db8141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set dimension: (2034, 2000)\n",
      "Test set dimension: (1353, 2000)\n"
     ]
    }
   ],
   "source": [
    "X_train = newsgroups_train.data   #학습 데이터셋 문서\n",
    "y_train = newsgroups_train.target #학습 데이터셋 라벨\n",
    "\n",
    "X_test = newsgroups_test.data     #검증 데이터셋 문서\n",
    "y_test = newsgroups_test.target   #검증 데이터셋 라벨\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(max_features=2000, min_df=5, max_df=0.5)\n",
    "\n",
    "X_train_cv = cv.fit_transform(X_train) # train set을 변환\n",
    "print('Train set dimension:', X_train_cv.shape) \n",
    "X_test_cv = cv.transform(X_test) # test set을 변환\n",
    "print('Test set dimension:', X_test_cv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0018fc9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1990</th>\n",
       "      <th>1991</th>\n",
       "      <th>1992</th>\n",
       "      <th>1993</th>\n",
       "      <th>1994</th>\n",
       "      <th>1995</th>\n",
       "      <th>1996</th>\n",
       "      <th>1997</th>\n",
       "      <th>1998</th>\n",
       "      <th>1999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1348</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1349</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1350</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1351</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1352</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1353 rows × 2000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2     3     4     5     6     7     8     9     ...  1990  \\\n",
       "0        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "1        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "2        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "3        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "4        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "1348     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "1349     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "1350     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "1351     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "1352     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "\n",
       "      1991  1992  1993  1994  1995  1996  1997  1998  1999  \n",
       "0        0     0     0     0     0     0     0     0     0  \n",
       "1        0     0     0     0     0     0     0     0     0  \n",
       "2        0     0     0     0     0     0     0     0     0  \n",
       "3        0     0     0     3     0     0     0     0     0  \n",
       "4        0     0     0     0     0     0     0     0     0  \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "1348     0     0     0     1     0     0     0     0     0  \n",
       "1349     0     0     0     1     0     0     0     0     0  \n",
       "1350     0     0     0     1     0     0     0     0     0  \n",
       "1351     0     0     0     0     0     0     0     0     0  \n",
       "1352     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[1353 rows x 2000 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(X_test_cv.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98aa1167",
   "metadata": {},
   "source": [
    "## 문서 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995dbf0d",
   "metadata": {},
   "source": [
    "### 나이브 베이즈 분류기(Naive Bayse Classifier)를 이용한 문서 분류\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88784fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.824\n",
      "Test set score: 0.732\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB #sklearn이 제공하는 MultinomialNB 를 사용\n",
    "NB_clf = MultinomialNB() # 분류기 선언\n",
    "\n",
    "NB_clf.fit(X_train_cv, y_train) #train set을 이용하여 분류기(classifier)를 학습\n",
    "\n",
    "print('Train set score: {:.3f}'.format(NB_clf.score(X_train_cv, y_train))) #train set에 대한 예측정확도를 확인\n",
    "print('Test set score: {:.3f}'.format(NB_clf.score(X_test_cv, y_test))) #test set에 대한 예측정확도를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f179c990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#First document and label in test data: TRry the SKywatch project in  Arizona. 2\n",
      "#Second document and label in test data: The Vatican library recently made a tour of the US.\n",
      " Can anyone help me in finding a FTP site where this collection is \n",
      " available. 1\n",
      "#Predicted labels: [2 1]\n",
      "#Predicted categories: sci.space comp.graphics\n"
     ]
    }
   ],
   "source": [
    "#예측문제\n",
    "\n",
    "print('#First document and label in test data:', X_test[0], y_test[0])\n",
    "print('#Second document and label in test data:', X_test[1], y_test[1])\n",
    "\n",
    "pred = NB_clf.predict(X_test_cv[:2])\n",
    "\n",
    "print('#Predicted labels:', pred)\n",
    "print('#Predicted categories:', newsgroups_train.target_names[pred[0]], newsgroups_train.target_names[pred[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88b6d03a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.862\n",
      "Test set score: 0.741\n"
     ]
    }
   ],
   "source": [
    "#TF-IDF사용 \n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#CountVectorizer와 동일한 인수를 사용\n",
    "tfidf = TfidfVectorizer(max_features=2000, min_df=5, max_df=0.5) \n",
    "X_train_tfidf = tfidf.fit_transform(X_train) # train set을 변환\n",
    "X_test_tfidf = tfidf.transform(X_test) # test set을 변환\n",
    "\n",
    "NB_clf.fit(X_train_tfidf, y_train) #tfidf train set을 이용하여 분류기(classifier)를 새로 학습\n",
    "print('Train set score: {:.3f}'.format(NB_clf.score(X_train_tfidf, y_train))) #train set에 대한 예측정확도를 확인\n",
    "print('Test set score: {:.3f}'.format(NB_clf.score(X_test_tfidf, y_test))) #test set에 대한 예측정확도를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dccc69a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt.atheism: you, not, are, be, this, have, as, what, they, if\n",
      "comp.graphics: you, on, graphics, this, have, any, can, or, with, thanks\n",
      "sci.space: space, on, you, be, was, this, as, they, have, are\n",
      "talk.religion.misc: you, not, he, are, as, this, be, god, was, they\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sususu\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:101: FutureWarning: Attribute coef_ was deprecated in version 0.24 and will be removed in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#카테고리별로 영향을 많이 미친 특성(단어)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def top10_features(classifier, vectorizer, categories):\n",
    "    feature_names = np.asarray(vectorizer.get_feature_names())\n",
    "    for i, category in enumerate(categories):\n",
    "        # 역순으로 정렬하기 위해 계수에 음수를 취해서 정렬 후 앞에서부터 10개의 값을 반환\n",
    "        top10 = np.argsort(-classifier.coef_[i])[:10]\n",
    "        # 카테고리와 영향이 큰 특성 10개를 출력\n",
    "        print(\"%s: %s\" % (category, \", \".join(feature_names[top10])))\n",
    "\n",
    "top10_features(NB_clf, tfidf, newsgroups_train.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c076c52",
   "metadata": {},
   "source": [
    "### 의사결정나무를 이용한 문서 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6304f209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Decision Tree train set score: 0.977\n",
      "#Decision Tree test set score: 0.536\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state=7)\n",
    "tree.fit(X_train_tfidf, y_train)\n",
    "print('#Decision Tree train set score: {:.3f}'.format(tree.score(X_train_tfidf, y_train)))\n",
    "print('#Decision Tree test set score: {:.3f}'.format(tree.score(X_test_tfidf, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a1041e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Decision Tree train set score: 0.807\n",
      "#Decision Tree test set score: 0.551\n"
     ]
    }
   ],
   "source": [
    "# 가지치기\n",
    "\n",
    "tree2 = DecisionTreeClassifier(min_samples_split=50,random_state=7)\n",
    "#tree2 = DecisionTreeClassifier(max_depth=2,random_state=7)\n",
    "\n",
    "tree2.fit(X_train_tfidf, y_train)\n",
    "print('#Decision Tree train set score: {:.3f}'.format(tree2.score(X_train_tfidf, y_train)))\n",
    "print('#Decision Tree test set score: {:.3f}'.format(tree2.score(X_test_tfidf, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27e9ea2",
   "metadata": {},
   "source": [
    "### 불용어 제거하여 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7bbb064d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 library들을 import\n",
    "from nltk.corpus import stopwords\n",
    "cachedStopWords = stopwords.words(\"english\")\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import re\n",
    "\n",
    "RegTok = RegexpTokenizer(\"[\\w']{3,}\") # 정규포현식으로 토크나이저를 정의\n",
    "english_stops = set(stopwords.words('english')) #영어 불용어를 가져옴\n",
    "\n",
    "def tokenizer(text):\n",
    "    tokens = RegTok.tokenize(text.lower()) #이렇게 해도 되는지 확인\n",
    "    # stopwords 제외\n",
    "    words = [word for word in tokens if (word not in english_stops) and len(word) > 2]\n",
    "    # portr stemmer 적용\n",
    "    features = (list(map(lambda token: PorterStemmer().stem(token),words)))\n",
    "    return features\n",
    "\n",
    "tfidf = TfidfVectorizer(tokenizer=tokenizer, max_features=2000, min_df=5, max_df=0.5) # 새로 정의한 토크나이저 사용\n",
    "X_train_tfidf = tfidf.fit_transform(X_train) # train set을 변환\n",
    "X_test_tfidf = tfidf.transform(X_test) # test set을 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9ea34999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.879\n",
      "Test set score: 0.746\n"
     ]
    }
   ],
   "source": [
    "#나이브 베이즈 분류기 \n",
    "\n",
    "NB_clf = MultinomialNB() \n",
    "\n",
    "NB_clf.fit(X_train_tfidf, y_train) #train set을 이용하여 분류기(classifier)를 학습\n",
    "\n",
    "print('Train set score: {:.3f}'.format(NB_clf.score(X_train_tfidf, y_train))) #train set에 대한 예측정확도를 확인\n",
    "print('Test set score: {:.3f}'.format(NB_clf.score(X_test_tfidf, y_test))) #test set에 대한 예측정확도를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3c6cd9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Decision Tree train set score: 0.880\n",
      "#Decision Tree test set score: 0.603\n"
     ]
    }
   ],
   "source": [
    "#의사결정모델 분류기\n",
    "\n",
    "tree3 = DecisionTreeClassifier(min_samples_split=50,random_state=7)\n",
    "#tree3 = DecisionTreeClassifier(random_state=7)\n",
    "#tree3 = DecisionTreeClassifier(max_depth=2,random_state=7)\n",
    "\n",
    "tree3.fit(X_train_tfidf, y_train)\n",
    "print('#Decision Tree train set score: {:.3f}'.format(tree3.score(X_train_tfidf, y_train)))\n",
    "print('#Decision Tree test set score: {:.3f}'.format(tree3.score(X_test_tfidf, y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
